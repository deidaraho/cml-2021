{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment (High-Level) Solution\n",
    "\n",
    "## What? Break the Dependency\n",
    "\n",
    "__How? Export the Model and Move It__\n",
    "\n",
    "This brings us, for better or worse to a choice of what format to use.\n",
    "\n",
    "As always, it's a compromise to accommodate ease of use, performance, portability, \"openness,\" etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Amalgamation\n",
    "\n",
    "The simplest form of export is \"amalgamation\" ... in which case the model and all necessary code to run are emitted as one big chunk.\n",
    "\n",
    "In some cases, it's a single source code file that can be compiled on nearly any platform as a standalone program.\n",
    "  * Classic amalgamation: MXNet + model code https://mxnet.apache.org/faq/smart_device.html#amalgamation-making-the-whole-system-a-single-file\n",
    "\n",
    "In other cases, it's a chunk of consumable IR code that can be consumed in a common runtime:\n",
    "  * H2O POJO export https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/productionizing.rst#pojo-quick-start\n",
    "  * TVM IR https://docs.tvm.ai/tutorials/cross_compilation_and_rpc.html\n",
    "    * If we haven't already looked at it, make a mental note to explore TVM at some point: https://tvm.ai/about\n",
    "\n",
    "And sometimes ... it's a coder implementing a model by hand and compiling it! (For simple, popular models, like linear/logistic regression, it's pretty easy once you have the model params.)\n",
    "\n",
    "__Pros and Cons__\n",
    "\n",
    "Pros:\n",
    "* Easy-to-understand concept\n",
    "* Fairly portable\n",
    "* Can be compact and performant\n",
    "  * May be a good choice for extremely constrained embedded environments\n",
    "\n",
    "Cons:\n",
    "* Not interoperable with other high-level environments\n",
    "* Not easily human readable, diffable, manageable in a CMS or version control\n",
    "* Violates separation of code from data\n",
    "* May not fit in well with enterprise manageability and operations needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single-Product Format\n",
    "\n",
    "I.e., a format which serves a specific product ecosystem, but is not intended to interoperate with other systems nor serve as a \"standard\"\n",
    "\n",
    "*Examples:*\n",
    "\n",
    "__SparkML + MLeap__\n",
    "* MLeap supports Spark, some scikit-learn models and some TensorFlow models\n",
    "* Represents models in a \"MLeap Bundle\"\n",
    "* MLeap runtime is a JAR that can run in any Java application (or by with a lightweight scoring wrapper provided by MLeap)\n",
    "  \n",
    "__TensorFlow + TensorFlow Serving__\n",
    "* TensorFlow models (created directly with TensorFlow or with Keras) serialize to a TF-specific protocol buffer representation\n",
    "* TensorFlow Serving loads the latest version of a model\n",
    "    * TF Serving exposes a gRPC service and, in the latest version, a REST endpoint\n",
    "\n",
    "__TensorFlow + FlatBuffers + TFLite__\n",
    "* FlatBuffers is an \"open\" format with multiple collaborators\n",
    "* Targets iOS and Android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Existing Standard Format: PMML\n",
    "\n",
    "<img src=\"https://materials.s3.amazonaws.com/i/PMML_Logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMML has existed for over 20 years, and is used widely throughout the world. \n",
    "\n",
    "It has many advantages, but is not perfect.\n",
    "\n",
    "Pros:\n",
    "* In wide use / well-accepted / large community\n",
    "* Core XML dialect can be human readable\n",
    "* Models can be processed/managed by text-based tools (VCS/CMS/etc.)\n",
    "* Covers the majority of modeling cases companies use today\n",
    "* *Formally* interoperable (reading/writing the container file format)\n",
    "\n",
    "Cons:\n",
    "* Support for production of models in the open-source world is spotty\n",
    "* Support for consuming models in the OSS is sparse/minimal\n",
    "* Importance of modern open-source tooling has been dragging PMML down\n",
    "* Some modern model types and pipelines are not supported, or not supported efficiently/compactly\n",
    "* *Semantic* interop is only marginally existent\n",
    "\n",
    "In practice, PMML -- even with commercial/enterprise, supported products -- is more like USB C than USB 3. \n",
    "\n",
    "I.e., like USB C, it's very versatile in theory, and the plug always fits, but that tells you little or nothing about whether the two devices connected can have any conversation, let alone the specific conversation you need them to have.\n",
    "\n",
    "Despite its imperfections, it has many advantages over single-product formats, so we often use it even if it cannot fulfil a promise of being the \"universal\" tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example__\n",
    "\n",
    "Here is an example of a logistic regression classifier trained using R on the Iris dataset:\n",
    "\n",
    "(http://dmg.org/pmml/pmml_examples/rattle_pmml_examples/IrisMultinomReg.xml)\n",
    "\n",
    "<img src=\"https://materials.s3.amazonaws.com/i/UFJlBqq.png\" width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where do we get a PMML model?\n",
    "\n",
    "A partial list of products supporting PMML is at http://dmg.org/pmml/products.html\n",
    "\n",
    "Focusing on the *producing PMML* side, we can see there are a lot of products that can create PMML, even if most of them are commercial or have effectively commercial licensing schemes (e.g. JPMML).\n",
    "\n",
    "In the open-source world (again, excluding AGPL code like JPMML), we have\n",
    "* R -- strongest open-source export support\n",
    "* Spark -- very limited support: the listed models are only supported under the *old/deprecated* RDD MLlib API\n",
    "  * There is work in progress to add PMML export to the new API but it has just begun and may not make progress\n",
    "* Python -- aside from the wrapper around the above-mentioned JPMML, the best option today is\n",
    "  * https://nyoka-pmml.github.io/nyoka/index.html\n",
    "  \n",
    "It is important to note that\n",
    "* although there are plenty of commercial products with at least some PMML support\n",
    "* and although large enterprises can (and for support/legal reasons prefer to) pay for a product\n",
    "* the lack of openness and community is leaving commercial-only ML tooling far behind\n",
    "  * e.g., all of the top deep learning tools are FOSS\n",
    "  * this means most of the performance-focused work is tied to the FOSS tools\n",
    "  * scaling is owned by FOSS (kubeflow, Horovod, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we run a PMML model?\n",
    "\n",
    "Permissive OSS support for running PMML models is effectively nonexistent, so we need architect in tandem with business decisions around a vendor's analytics server product. These business decisions will go beyond the licensing and support, because they will affect all of our enterprise architectures: hardware, network, software, managment/monitoring/operations, reliability/contiuity, compliance etc.\n",
    "\n",
    "However, we can make use of the AGPL code in JPMML for demonstration purposes.\n",
    "\n",
    "#### JPMML\n",
    "\n",
    "JPMML (https://github.com/jpmml) is a set of AGPL OSS projects that \n",
    "* form the de facto Java implementation of PMML\n",
    "* offer interop with key FOSS tools like Apache Spark, R, Scikit-learn, XGBoost, TensorFlow, etc.\n",
    "* provide easy scoring in your own apps, or using a \"scoring wrapper\" or hosted in the cloud\n",
    "* is maintained and licensed in connection with https://openscoring.io/ \n",
    "* *note: there is an older, abandoned, version of JPMML under a more friendly Apache 2.0 license*\n",
    "  * this older version has many features and might be suitable for some organizations with a higher risk/ownership appetite\n",
    "  * https://github.com/jpmml/jpmml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Next-Gen Standard Format: PFA\n",
    "\n",
    "<img src=\"https://materials.s3.amazonaws.com/i/PFA_Logo-200x200.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PFA (Portable Format for Analytics) is a Modern Replacement for PMML\n",
    "\n",
    "##### \"As data analyses mature, they must be hardened — they must have fewer dependencies, a more maintainable structure, and they must be robust against errors.\" - DMG\n",
    "\n",
    "PFA, created in 2015, is intended to improve upon PMML.\n",
    "\n",
    "From http://dmg.org/pfa/docs/motivation/:\n",
    "\n",
    "*Tools such as Hadoop and Storm provide automated data pipelines, separating the data flow from the functions that are performed on data (mappers and reducers in Hadoop, spouts and bolts in Storm). Ordinarily, these functions are written in code that has access to the pipeline internals, the host operating system, the remote filesystem, the network, etc. However, all they should do is math.*\n",
    "\n",
    "*PFA completes the abstraction by encapsulating these functions as PFA documents. From the point of view of the pipeline system, the documents are configuration files that may be loaded or replaced independently of the pipeline code.*\n",
    "\n",
    "*This separation of concerns allows the data analysis to evolve independently of the pipeline. Since scoring engines written in PFA are not capable of accessing or manipulating their environment, they cannot jeopardize the production system. Data analysts can focus on the mathematical correctness of their algorithms and security reviews are only needed when the pipeline itself changes.*\n",
    "\n",
    "*This decoupling is important because statistical models usually change more quickly than pipeline frameworks. Model details are often tweaked in response to discoveries about the data and models frequently need to be refreshed with new training samples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://materials.s3.amazonaws.com/i/KuQPUbx.png\" width=800>\n",
    "\n",
    "(summarized from DMG)\n",
    "\n",
    "#### Overview of PFA capabilities\n",
    "\n",
    "PFA flexibility:\n",
    "* Control structures, such as conditionals, loops, and user-defined functions\n",
    "* Entirely expressed within JSON, and can therefore be easily generated and manipulated by other programs\n",
    "* Fine-grained function library supporting extensibility callbacks\n",
    "* Scoring engines can share data or update external variables, such as entries in a database.\n",
    "\n",
    "The following contribute to PFA’s safety:\n",
    "\n",
    "* Strict numerical compatibility: the same PFA document and the same input results in the same output, regardless of platform.\n",
    "* Spec only defines functions that transform data. I/O is all controlled by the host system.\n",
    "* Type system that can be statically checked. ... This system has a type-safe null and PFA only performs type-safe casting, which ensure that missing data never cause run-time errors.\n",
    "* The callbacks that generalize PFA’s statistical models are not first-class functions\n",
    "  * The set of functions that a PFA document might call can be predicted before it runs\n",
    "  * A PFA host may choose to only allow certain functions.\n",
    "* The semantics of shared data guarantee that data are never corrupted by concurrent access and scoring engines do not enter deadlock. \n",
    "  * The host can also statically determine which shared variables may be modified by a scoring engine, rather than at run-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example__\n",
    "\n",
    "Here are some data records:\n",
    "\n",
    "<img src=\"https://materials.s3.amazonaws.com/i/vsvToXy.png\" width=600>\n",
    "\n",
    "And a PFA document which returns the square-root of the sum of the squares of a record's x, y, and z values:\n",
    "\n",
    "<img src=\"https://materials.s3.amazonaws.com/i/tIlag9o.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example -- along with numerous other tutorials -- can be viewed, *modified*, and run live online at http://dmg.org/pfa/docs/tutorial2/ and other dmg.org pages.\n",
    "\n",
    "Although it may not be obvious from this small example, PFA is effectively a programming language, albeit a restricted one, and as such can express complex transformations and aggregations of data. The PFA document is a serialized representation or description of a scoring engine, of which one or more instances can be created by a runtime.\n",
    "\n",
    "That said, it is still intended to be a machine-generated and machine-consumed document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "01-Model-Formats",
  "notebookId": 2375086480049053
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
